from xml.etree.ElementTree import parse, Element, SubElement, Comment, tostring, fromstring
import xml.etree.ElementTree as ET
import urllib.request
import datetime
from pathlib import Path
from urllib.request import urlopen, Request


def seve_opml(nodes, output_path):
    generated_on = str(datetime.datetime.now())

    # Configure one attribute with set()
    root = Element('opml')
    root.set('version', '1.0')

    root.append(Comment('Generated by ElementTree_csv_to_xml.py for PyMOTW'))

    head = SubElement(root, 'head')
    title = SubElement(head, 'title')
    title.text = 'My Podcasts'
    dc = SubElement(head, 'dateCreated')
    dc.text = generated_on
    dm = SubElement(head, 'dateModified')
    dm.text = generated_on

    body = SubElement(root, 'body')
    current_group = None
    for node in nodes:
        name = node.attrib.get('text')
        url = node.attrib.get('xmlUrl')
        htmlUrl = node.attrib.get('htmlUrl')
        if name and url:
            print('  %s' % name)
            print('    %s' % url)
            print('    %s' % htmlUrl)
            SubElement(current_group, 'outline',
                       {'text': name,
                        'xmlUrl': url,
                        'htmlUrl': htmlUrl,
                        })
        else:
            current_group = SubElement(body, 'outline', {'text': name})
            print(name)

    et = ET.ElementTree()
    et._setroot(root)
    et.write(output_path)


def read_opml(file_path):


    my_file = Path(file_path)
    if my_file.is_file() is False:
        print("파일이 없습니다.")
        return -1

    with open(file_path, 'rt') as f:
        tree = parse(f)

    nodes = []
    for node in tree.iter('outline'):
        nodes.append(node)

    headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) ' 
                      'AppleWebKit/537.11 (KHTML, like Gecko) '
                      'Chrome/23.0.1271.64 Safari/537.11',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',
        'Accept-Encoding': 'none',
        'Accept-Language': 'en-US,en;q=0.8',
        'Connection': 'keep-alive'}

    for node in nodes:
        name = node.attrib.get('text')
        url = node.attrib.get('xmlUrl')
        if name and url:

            rss_request = Request(url=url, headers=headers)
            rss_data = urlopen(rss_request).read()


            reddit_root = fromstring(rss_data)
            item = reddit_root.findall('channel/item')

            reddit_feed = []
            for entry in item:
                pubDate = entry.findtext('pubDate')
                reddit_feed.append([pubDate])

            if len(reddit_feed) > 0 and len(reddit_feed[0]) > 0:
                first_date = reddit_feed[0][0]

                if first_date.find("2018") >= 0 or first_date.find("2019") >= 0:
                    continue
                else:
                    nodes.remove(node)
            else:
                nodes.remove(node)

    return nodes


def main():
    nodes = read_opml("./feed.opml")
    if type(nodes) == list():
        seve_opml(nodes, "output.opml")


if __name__ == "__main__":
    main()
